nwarmington1
thats right

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
library(lubridate) 
library(Lock5Data)

# Import data
chicago <- readRDS("chicago.rds")
heroes <- read_csv("heroes.csv")
powers <- read_csv("powers.csv")
```

## Introduction

As a group, pick one or two of the following questions to explore. Each question has at leat 2 sub-questions. 

After you answer each sub-question, save and commit your changes (I recommend knitting at this point to make sure your code runs). At the end of each larger question, push your changes to GitHub and verify that your project on GitHub updated.

You do not need to correctly solve every part of the question; the goal is to practice workflow with RStudio + GitHub. 

# Questions

## I. Data Joins Exercise 

Superpowers challenge problem: this is a question that combines skills from chapter 5 (data transformation) and chapter 13 (joins). 

Between DC and Marvel, which publisher's heroes tend to have more powers? Let's compare visually and numerically.

To answer this question, you will need to:

#### Question 1

Filter the heroes data to only include Marvel or DC. You can also eliminate the DC version of Captain Marvel.

```{r}
marv_DC <- heroes %>%
  group_by(Publisher)%>%
  filter(Publisher == "Marvel Comics" | Publisher == "DC Comics" )
```


#### Question 2

Create a new variable called "num_powers" in the powers data set counting the number of powers each character has. (This is tricky; there are multiple ways to approach this. You may want to play with the rowSums() function, or see Boern's answer [here](https://stackoverflow.com/questions/28873057/sum-across-multiple-columns-with-dplyr)).

```{r}
tmp_powers <- powers %>% 
  mutate(num_powers = rowSums(.[2:168]))
head(tmp_powers)
```



#### Question 3


Join the two data sets together by character name and only keep name, publisher, and number of powers

```{r}

joined_heroes <- left_join(marv_DC, tmp_powers, by = c("name" = "hero_names")) %>%
  select(name, Publisher, num_powers)
joined_heroes
```


#### Question 4

Group by publisher and look at the distributions of numbers of powers within each publisher by creating summary tables (min, median, mean, max)

```{r}
sum_table <- joined_heroes%>%
  group_by(Publisher)%>%
  summarize(min_powers = min(num_powers, na.rm = TRUE),
            med_powers = median(num_powers, na.rm = TRUE),
            mean_powers = mean(num_powers, na.rm = TRUE),
            max_powers = max(num_powers, na.rm = TRUE))
sum_table
```


#### Question 5

Create a graph such as a histogram or boxplot showing the numbers of powers per character for Marvel vs DC. 

```{r}
ggplot(data = joined_heroes)+
  geom_boxplot(mapping = aes(x = Publisher, y = num_powers))
```


#### Question 6

Write a couple sentences to compare the distributions and decide if one publisher seems to have characters with more powers overall.

__Your answer:__
DC seems to give its heroes more powers than Marvel. Dc has a higher median, mean, and maximum number of powers given to heroes. The spread for DC in the boxplot is also longer, with the greatest 50 % of the powers being higher than Marvel.





#### Question 7

Write a couple sentences critiquing this approach. Discuss at least one major problem that prevents our code from actually measuring what we are trying to measure.

__Your answer:__
The main issue with this method is that it cannot work with NA values. If DC has many more NA values for its heroes, it may not be completely accurate to say that it gives its heroes more powers overall.




## II. Data Transformation Exercise

This is R for Data Science Exercise 5.5.

#### Question 1

1. Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because theyâ€™re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. (Hint: use modulo arithmetic and integer division; this is tricky!)

```{r}

```

#### Question 2

2. Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it? You don't actually need to fix it-- just explain how you would. (Hint: you may need to check the [documentation](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236) for the data)

```{r}

```

#### Question 3

3. Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?

```{r}

```

#### Question 4

4. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank(). 

```{r}

```




## III. Data Visualization Exercise

Let's make maps using ggplot and the `HappyPlanetIndex` data.

#### Question 1

1. See if you can adapt the textbook code for the map of New Zealand in section 3.9 to display a map of the world instead. Color the continents forest green with a lemon chiffon outline. Check out [this overview](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf) of colors in R if you want to play with the coloring a bit.

#### Question 2

2. Create a choropleth map of world happiness using `HappyPlanetIndex` data. In other words, create a world map, but instead of having every country the same color, apply different colors based on the happiness level of that country (using the Happiness variable in the HappyPlanetIndex data set). [This guide](https://www.datanovia.com/en/blog/how-to-create-a-map-using-ggplot2/) can get you started.


## IV. Data Transformation Discussion Exercises:


#### DE2. All about NA: 

Play around with NA values. What happens if you find the mean of a variable that has missing data? How can you avoid this? Discuss the pros and cons of each approach, and why you think R takes the default setting that it does.

Then dig deeper: Try to predict the results of each of the following pieces of code, and discuss whether the results make sense based on your previous thoughts about NA's.

```{r, eval = FALSE}
NA^0

NA | TRUE

NA & FALSE

NA | FALSE

NA * 0 

NA == NA

NA^FALSE | NA^TRUE

NA^FALSE & NA^TRUE
```

#### DE 3: Filter vs [ ]

We learned in week 1 and 2 to subset a vector or data frame using [ ]. This is very similar to filter, but the syntax is different. For instance, to select the flights which traveled the maximum distance, we could use:

```{r}
maxdist <- max(flights$distance, na.rm = TRUE)

flights[flights$distance == maxdist,]

```

Compare this approach to using filter. Which do you like better? Which is clearer? Consider also the following example, which may be relevant: 

(You may need to change the name of the temperature varaible below if you already completed BE3.)

```{r}
maxtemp <- max(chicago$tmpd, na.rm = TRUE)

chicago[chicago$tmpd == maxtemp,]
```

